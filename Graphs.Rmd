---
title: "DaSPPA product graphs"
subtitle: "This document will generate the requisite graphs and data analysis"
date: "2023-12-01"
output: pdf_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, echo = FALSE, warning = FALSE)
```


```{r, echo=TRUE}
library(tidyverse) 
library(reshape2)
library(dplyr)
library(ggrepel)
library(datawizard)
library(knitr) 
library(kableExtra)  
library(rnaturalearth)
library(sf)
library(stringi)
library(mapproj)
library(factoextra)
library(cluster)
library(klaR)
library(maps)
library(passport)
library(tidytext)
library(textdata)
library(purrr)

set.seed(25536)
```

### Data Preprocessing
```{r}
unvotes <- read.csv("data/dataverse_files/UNVotes.csv")
idealpointestimates <- read.csv("data/dataverse_files/IdealpointestimatesAll_Jul2023.csv")

#unvotes$date <- as.Date(unvotes$date)

un_vote_data <- unvotes |>
  dplyr::mutate(date = as.Date(date, format="%Y-%m-%d")) |> 
  dplyr::select(Country, date, resid, vote, importantvote, me, nu, di, hr, co, ec) |>
  dplyr::filter(date >= as.Date("2000-01-01", format="%Y-%m-%d"))



```


#### Pre-Training analysis
Using Elbow method and gap statistic, we aim to find the optimal cluster gap.
```{r, eval = FALSE}
gc()

df <- un_vote_data |> 
  dplyr::filter(ec == 1) |> 
  dplyr::select(Country, resid, vote, importantvote)

df <- na.omit(df)

dfm <- scale(df2 |> dplyr::select(resid, vote, importantvote))

fviz_nbclust(dfm, kmeans, method = "wss") +
      geom_vline(xintercept = 3, linetype = 2)+
      labs(subtitle = "Elbow method")

gc()

gap_stat <- clusGap(dfm, FUN = kmeans, nstart = 25, K.max = 10, B = 50)
fviz_gap_stat(gap_stat)
gc()
```
Lets use k=5 as it is a good compromise.

#### Fitting the k means model.
```{r}
k <- 5
gc()

df <- un_vote_data |> filter(importantvote == 1)
dfm <-na.omit(df)

data <- dfm |> dplyr::select(Country, resid, vote)
data_transposed <- data %>%
  spread(key = resid, value = vote)

dfm <-na.omit(data_transposed)
dfm2 <- dfm[, -1]


km.res <- kmeans(dfm2, centers = 5, nstart = 1000) 
fviz_cluster(km.res, data=dfm2, ellipse.type = "norm")

#km.res['Country']=labels
world2E <- ne_countries(scale="medium", returnclass = "sf")
#world2E <- st_make_valid(world2E)
#world2E <- st_simplify(world2E, dTolerance = 100)
#wrd <- world2E |> dplyr::mutate(Country = as_country_code(geounit, from="en",to = "iso3c"))

wrd <- world2E |> dplyr::mutate(Country = iso_a3)

```

```{r}

dfm['cluster']= km.res$cluster


wrdonly <- anti_join(wrd, dfm, by = "Country")
summary_1 <- wrdonly |> 
  dplyr::group_by(Country) |> 
  dplyr::summarize(count = n()) 

unvotesonly <- anti_join(dfm, wrd, by = "Country")
summary_2 <- unvotesonly |> 
  dplyr::group_by(Country) |> 
  dplyr::summarize(count= n()) 

summary_1
summary_2

country_group <- dfm |> dplyr::select(Country, cluster)


combined <- right_join(country_group, wrd, by = "Country")

combined <- combined |> mutate(cluster = as.character(cluster))


combined |> ggplot(aes(fill=cluster)) +
  geom_sf(aes(geometry=geometry)) +
  coord_sf() +
  guides(x = "none", y = "none") +
  labs(title = "Map: K Means grouping of UN Voting Alignment Groups",
    subtitle = "Model: k = 5, aligned on voting Yes/No/Abstain for every resolution",
    caption = "Using UN Votes Data.",
    x=NULL, y=NULL, fill="Alignment"
  ) 
```


### Part 2: Graph Network Analysis



### Part 3: Sentiment Analysis and Regression.
```{r}
presscon <- readxl::read_xlsx("data/Sentiment/CMFA_PressCon_v3.xlsx")

press_select <- presscon |> dplyr::select(question_lem, answer_lem, q_loc, a_loc)

```




```{r}
# Assuming your dataframe is named 'df' and has columns A and B
# Load a sentiment lexicon (e.g., AFINN) for sentiment analysis
afinn <- get_sentiments("afinn")

# Function to calculate sentiment for a row
calculate_row_sentiment <- function(row) {
  sentiment_question <- row %>%
    dplyr::select(question_lem) %>%
    unnest_tokens(word, question_lem) %>%
    inner_join(afinn) %>%
    summarize(sentiment_question = sum(value))

  sentiment_answer <- row %>%
    dplyr::select(answer_lem) %>%
    unnest_tokens(word, answer_lem) %>%
    inner_join(afinn) %>%
    summarize(sentiment_answer = sum(value))

  overall_sentiment <- case_when(
    sentiment_question$sentiment_question >= 0 ~ sentiment_answer$sentiment_answer,
    sentiment_question$sentiment_question < 0 ~ -sentiment_answer$sentiment_answer
  )

  return(cbind(row, sentiment_question, sentiment_answer, overall_sentiment))
}

# Apply the function row-wise to the dataframe
sentiment_speech <- press_select %>%
  group_by(row_number()) %>%
  do(calculate_row_sentiment(.))
```


```{r}
# TODO: Process countries mentioned: if countries appear in A and B locations
sentiment_speech <- sentiment_speech |> mutate(qloctrim = lapply(strsplit(q_loc, ";"), function(x) trimws(x))
) 

sentiment_speech <- sentiment_speech |> mutate(aloctrim = lapply(strsplit(a_loc, ";"), function(x) trimws(x))
) 

sentiment_speech <- sentiment_speech |> mutate(qloctrim =
  if_else(!is.vector(qloctrim), c(qloctrim), qloctrim)
) 


sentiment_speech <- sentiment_speech |> mutate(aloctrim =
  if_else(!is.vector(aloctrim), c(aloctrim), aloctrim)
) 

sentiment_speech <- sentiment_speech |> mutate(countries = pmap(list(qloctrim, aloctrim), intersect))

append_sentiment <- function(clist, sentiment) {
  data.frame(target_country = clist, overall_sentiment = sentiment)
}

sentiment_china_to_country <- sentiment_speech |> 
  dplyr::select(countries, overall_sentiment) |>
  unnest(countries) |>
  filter(!countries %in% c("China", "-"))

# TODO: Now, group and calculate average sentiment.
sentiment_china_grouped <- sentiment_china_to_country |>
  dplyr::select(countries, overall_sentiment) |>
  group_by(countries) |>
  summarize(avg_sentiment = mean(overall_sentiment))

sentiments_final <- sentiment_china_grouped |> 
  mutate(iso3c = as_country_code(countries, from="en",to = "iso3c")) |>
  group_by(iso3c) |>
  summarize(avg_sentiment = mean(avg_sentiment))
           

# TODO: NOTE: Limitations section for Nisaar: some records are coded as Peoples Republic of Vietnam, Republic of india, etc. Some other places are coded wrong. Very hard to recode everything. Missing out on some sentiment relevant speeches.

```


```{r}
# TODO: Calculate absolute distance between pairs of countries.
# Using idealpointestimates, use IdealPointAll to calculate the ideal point difference (absolute value) for every pair of countries.
# Use most recent session in the UN.
current_ideals_countries <- idealpointestimates |>
  filter(session ==77)

relevant_ideals <- current_ideals_countries |>
  dplyr::select(iso3c, IdealPointAll)

china_row <- relevant_ideals |> filter(iso3c == "CHN")

china_paired_sentiments <- relevant_ideals |>
  filter(iso3c != "CHN") |>
  mutate(IdealAbsDiff = abs(IdealPointAll - china_row$IdealPointAll))

# Final Step Conduct Join the data, and run regression line with x=UNIdeal y=sentiment
joined <- inner_join(china_paired_sentiments, sentiments_final, "iso3c") |>
  dplyr::select(IdealAbsDiff, avg_sentiment) 

# Data has been normalized.

j2 <- joined |>
  scale()

jd <- as.data.frame(j2)

model <- lm(avg_sentiment ~ IdealAbsDiff, data = jd)
summary(model)

jd |> ggplot(aes(IdealAbsDiff, avg_sentiment)) +
  geom_point() +
  geom_smooth(method='lm') +
  labs(
    title = "Regression: UN Vote Alignment on Sentiment for pther countries with China",
    subtitle = "Model: OLS - Sentiment ~ IdealDifference",
    caption = "Using UN Votes and China MFA Press Release Data.",
    x = "UN Voting Ideals Absolute Difference",
    y = "Average Sentiment of China"
  )
```























